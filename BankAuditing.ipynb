{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macronald88/ai-audit-assistant/blob/main/BankAuditing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5FCF8kftkBd"
      },
      "source": [
        "**0502_Data Consultants & Architects**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSrTdlxItEa1"
      },
      "source": [
        "**Use Case: AI-Powered Expert System for Automated Audit Assistance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS4fmcQiuczj"
      },
      "source": [
        "**Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkPm-q6uin2"
      },
      "source": [
        "Auditors spend a large amount of time manually checking documents, matching records, and writing reports. These tasks are repetitive, error-prone, and slow, especially when dealing with high volumes of data. There is a need for a smart system that can analyze and explain audit data quickly and accurately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5sXwsqxqtp1"
      },
      "source": [
        "# SET-UP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gMAMPK5_d3zR",
        "outputId": "71dc7741-03a8-4cf9-8298-9e75a747762b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas openpyxl openai\n",
        "!pip install -q streamlit\n",
        "!pip install openai\n",
        "!pip install pandas openpyxl openai\n",
        "!pip install streamlit pandas\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import openai\n",
        "import io\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7e4Agvyr1EJ",
        "outputId": "71f8a0fd-3a64-492f-a880-af16cdc706a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4LJjMu_3buv"
      },
      "source": [
        "# AI Model Development (with Deep Learning and LLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeefkZWvu0De"
      },
      "source": [
        "# Source Files\n",
        "\n",
        "1.Bank statement -Generated by the Bank\n",
        "\n",
        "2.General leddger - Generated from the Accounting system.It contains all transactions from 1 July - 31 December\n",
        "\n",
        "3.Purchases Invoices - Generated from Accounting system(Detailed report by Suppliers)\n",
        "\n",
        "4.Receipts -Generated from the Point of Sale System/manually captured receipts register(note the POS is usually separeted from the accounting system)\n",
        "\n",
        "5.Sales - Generated from Accounting system(Detailed sales report by Customers)\n",
        "\n",
        "6.Supplier statements-Generated from Accounting system(Detailed sales report by Customers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su4iySOwYwxf"
      },
      "source": [
        "#2. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgPjckXgtAth"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "\n",
        "bank = pandas.read_csv('/content/drive/MyDrive/BUDT751/DATASETS/bank_statement.csv')\n",
        "ledger = pandas.read_csv('/content/drive/MyDrive/BUDT751/DATASETS/general_ledger.csv')\n",
        "purchase = pandas.read_csv('/content/drive/MyDrive/BUDT751/DATASETS/purchase_invoices.csv')\n",
        "receipts = pandas.read_csv('/content/drive/MyDrive/BUDT751/DATASETS/receipts.csv')\n",
        "sales = pandas.read_csv('/content/drive/MyDrive/BUDT751/DATASETS/sales_invoices.csv')\n",
        "suppliers = pandas.read_csv('/content/drive/MyDrive/BUDT751/DATASETS/supplier_statements.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Model Development (with Deep Learning and LLM)"
      ],
      "metadata": {
        "id": "srmK3P0vtZ56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import openai\n",
        "import io\n",
        "\n",
        "\n",
        "# --- 4.1 Data Loading and Preprocessing ---\n",
        "def load_data(file_path):\n",
        "    \"\"\"Loads data from a file-like object (like from st.file_uploader).\"\"\"\n",
        "    try:\n",
        "        # When using st.file_uploader, the file_path is a file-like object.\n",
        "        # You need to read from this object, not treat it as a string path.\n",
        "        df = pd.read_csv(file_path)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        # Catch potential errors during file reading\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return None # Return None or raise a specific error\n",
        "\n",
        "\n",
        "def preprocess_dates(df, date_columns):\n",
        "    \"\"\"Converts specified columns to datetime.\"\"\"\n",
        "    # Add a check if df is None in case load_data failed\n",
        "    if df is None:\n",
        "        print(\"Warning: Cannot preprocess dates, DataFrame is None.\")\n",
        "        return None\n",
        "    for col in date_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "        else:\n",
        "            print(f\"Warning: Date column '{col}' not found.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def clean_data(df):\n",
        "    \"\"\"Cleans data (drop duplicates, fill NaNs).\"\"\"\n",
        "    # Add a check if df is None\n",
        "    if df is None:\n",
        "        print(\"Warning: Cannot clean data, DataFrame is None.\")\n",
        "        return None\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.fillna(0)\n",
        "    return df\n",
        "\n",
        "\n",
        "# No need for prepare_data_for_dl and DL model functions\n",
        "# since we are focusing on rule-based checks\n",
        "\n",
        "\n",
        "# --- 4.3 LLM Integration for Explanation ---\n",
        "def get_llm_explanation(anomaly_data, context_data, anomaly_type=\"\"):\n",
        "    \"\"\"\n",
        "    Gets an explanation for the detected anomalies from an LLM.\n",
        "    \"\"\"\n",
        "    openai.api_key = \"YOUR_OPENAI_API_KEY\"  # Replace with your key\n",
        "\n",
        "    # Convert anomaly data to string\n",
        "    # Add checks if anomaly_data or context_data are None or not DataFrames\n",
        "    anomaly_data_str = \"\"\n",
        "    if isinstance(anomaly_data, pd.DataFrame):\n",
        "         anomaly_data_str = anomaly_data.to_string()\n",
        "\n",
        "    context_data_str = \"\"\n",
        "    if isinstance(context_data, pd.DataFrame):\n",
        "        context_data_str = context_data.to_string()\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert auditor.  The following data represents potentially anomalous\n",
        "    financial transactions:\n",
        "\n",
        "    Anomaly Type: {anomaly_type}\n",
        "\n",
        "    Anomalous Data:\n",
        "    {anomaly_data_str}\n",
        "\n",
        "    Context Data:\n",
        "    {context_data_str}\n",
        "\n",
        "    Explain why these transactions might be anomalous, and what further\n",
        "    investigation should be done.  Provide your explanation as a markdown list.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            model=\"gpt-3.5-turbo-instruct\",  # Or another suitable model\n",
        "            prompt=prompt,\n",
        "            max_tokens=500,\n",
        "            temperature=0.5,  # Adjust for desired randomness\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error getting LLM explanation: {e}\"\n",
        "\n",
        "\n",
        "# --- 4.4 Main Analysis Function ---\n",
        "def analyze_audit_data(bank_statement_file, supplier_statements_file,\n",
        "                       purchase_invoices_file, sales_invoices_file, receipts_file): # Order changed\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the audit data analysis.\n",
        "    1.  Loads and preprocesses data.\n",
        "    2.  Performs rule-based checks for the specified audit issues.\n",
        "    3.  Uses an LLM to explain any discrepancies.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load data using the load_data function, which should handle file-like objects\n",
        "        bank_statement_df = load_data(bank_statement_file)\n",
        "        supplier_statements_df = load_data(supplier_statements_file)\n",
        "        purchase_invoices_df = load_data(purchase_invoices_file)\n",
        "        sales_invoices_df = load_data(sales_invoices_file)\n",
        "        receipts_df = load_data(receipts_file)  # Load receipts data\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Error loading files: {e}\"}\n",
        "\n",
        "    # Check if any DataFrame failed to load\n",
        "    if any(df is None for df in [bank_statement_df, supplier_statements_df,\n",
        "                                 purchase_invoices_df, sales_invoices_df, receipts_df]):\n",
        "        return {\"error\": \"One or more files failed to load.\"}\n",
        "\n",
        "    # Preprocess dates\n",
        "    bank_statement_df = preprocess_dates(bank_statement_df, ['Date'])\n",
        "    supplier_statements_df = preprocess_dates(supplier_statements_df, ['Date'])\n",
        "    purchase_invoices_df = preprocess_dates(purchase_invoices_df, ['Date'])\n",
        "    sales_invoices_df = preprocess_dates(sales_invoices_df, ['Date'])\n",
        "    receipts_df = preprocess_dates(receipts_df, ['Date'])\n",
        "\n",
        "    # Clean data\n",
        "    bank_statement_df = clean_data(bank_statement_df)\n",
        "    supplier_statements_df = clean_data(supplier_statements_df)\n",
        "    purchase_invoices_df = clean_data(purchase_invoices_df)\n",
        "    sales_invoices_df = clean_data(sales_invoices_df)\n",
        "    receipts_df = clean_data(receipts_df)\n",
        "\n",
        "    # Check if any DataFrame became None after cleaning\n",
        "    if any(df is None for df in [bank_statement_df, supplier_statements_df,\n",
        "                                 purchase_invoices_df, sales_invoices_df, receipts_df]):\n",
        "        return {\"error\": \"Error during data cleaning.\"}\n",
        "\n",
        "\n",
        "    # --- Perform Audit Checks ---\n",
        "    # Ensure all required dataframes are not None before calling comparison functions\n",
        "    comparison_results = {}\n",
        "    if bank_statement_df is not None and supplier_statements_df is not None:\n",
        "        comparison_results = compare_bank_statement_supplier(bank_statement_df, supplier_statements_df)\n",
        "\n",
        "    missing_transactions_results = {}\n",
        "    if purchase_invoices_df is not None and sales_invoices_df is not None and receipts_df is not None:\n",
        "        missing_transactions_results = check_missing_transactions(purchase_invoices_df, sales_invoices_df, receipts_df)\n",
        "\n",
        "    receipts_comparison_results = {}\n",
        "    if bank_statement_df is not None and receipts_df is not None:\n",
        "        receipts_comparison_results = compare_bank_statement_receipts(bank_statement_df, receipts_df)\n",
        "\n",
        "\n",
        "    # --- Get LLM Explanations ---\n",
        "    # Ensure dataframes for LLM are not None before concatenating\n",
        "    supplier_anomaly_data = pd.DataFrame()\n",
        "    if \"supplier_payments_not_on_bank\" in comparison_results and \"bank_statement_payments_not_on_supplier\" in comparison_results and \"amount_differences\" in comparison_results:\n",
        "        supplier_anomaly_data = pd.concat([\n",
        "            comparison_results[\"supplier_payments_not_on_bank\"],\n",
        "            comparison_results[\"bank_statement_payments_not_on_supplier\"],\n",
        "            comparison_results[\"amount_differences\"]\n",
        "        ])\n",
        "    supplier_context_data = pd.DataFrame()\n",
        "    if bank_statement_df is not None and supplier_statements_df is not None:\n",
        "         supplier_context_data = pd.concat([bank_statement_df, supplier_statements_df])\n",
        "\n",
        "\n",
        "    llm_explanation_supplier = get_llm_explanation(\n",
        "        supplier_anomaly_data,\n",
        "        supplier_context_data,\n",
        "        \"Bank vs. Supplier Statement Discrepancies\"\n",
        "    )\n",
        "\n",
        "    missing_anomaly_data = pd.DataFrame()\n",
        "    if \"missing_purchase_invoices\" in missing_transactions_results and \"missing_sales_invoices\" in missing_transactions_results and \"missing_receipts\" in missing_transactions_results:\n",
        "        missing_anomaly_data = pd.DataFrame({\n",
        "            \"Missing Purchase Invoices\": [len(missing_transactions_results[\"missing_purchase_invoices\"])],\n",
        "            \"Missing Sales Invoices\": [len(missing_transactions_results[\"missing_sales_invoices\"])],\n",
        "            \"Missing Receipts\": [len(missing_transactions_results[\"missing_receipts\"])]\n",
        "        })\n",
        "\n",
        "    missing_context_data = pd.DataFrame()\n",
        "    if purchase_invoices_df is not None and sales_invoices_df is not None and receipts_df is not None:\n",
        "        missing_context_data = pd.concat([purchase_invoices_df, sales_invoices_df, receipts_df])\n",
        "\n",
        "\n",
        "    llm_explanation_missing = get_llm_explanation(\n",
        "        missing_anomaly_data,\n",
        "        missing_context_data,\n",
        "        \"Missing Transactions\"\n",
        "    )\n",
        "\n",
        "    receipts_anomaly_data = pd.DataFrame()\n",
        "    if \"receipts_not_on_bank\" in receipts_comparison_results and \"bank_statement_not_on_receipts\" in receipts_comparison_results and \"amount_differences\" in receipts_comparison_results:\n",
        "        receipts_anomaly_data = pd.concat([\n",
        "            receipts_comparison_results[\"receipts_not_on_bank\"],\n",
        "            receipts_comparison_results[\"bank_statement_not_on_receipts\"],\n",
        "            receipts_comparison_results[\"amount_differences\"]\n",
        "        ])\n",
        "\n",
        "    receipts_context_data = pd.DataFrame()\n",
        "    if bank_statement_df is not None and receipts_df is not None:\n",
        "        receipts_context_data = pd.concat([bank_statement_df, receipts_df])\n",
        "\n",
        "    llm_explanation_receipts = get_llm_explanation(\n",
        "        receipts_anomaly_data,\n",
        "        receipts_context_data,\n",
        "        \"Bank vs. Receipts Discrepancies\"\n",
        "    )\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"bank_supplier_comparison\": comparison_results,\n",
        "        \"missing_transactions\": missing_transactions_results,\n",
        "        \"bank_receipts_comparison\": receipts_comparison_results,\n",
        "        \"llm_explanation_supplier\": llm_explanation_supplier,\n",
        "        \"llm_explanation_missing\": llm_explanation_missing,\n",
        "        \"llm_explanation_receipts\": llm_explanation_receipts\n",
        "    }\n",
        "\n",
        "\n",
        "# --- 4.5 Helper Functions (Rule-Based Checks) ---\n",
        "def check_missing_transactions(purchase_invoices_df, sales_invoices_df, receipts_df):\n",
        "    \"\"\"Checks for missing transactions.\"\"\"\n",
        "    def find_missing(df, id_col):\n",
        "        if df is None or id_col not in df.columns:\n",
        "            return []\n",
        "        # Ensure the ID column is numeric before sorting and finding min/max\n",
        "        if not pd.api.types.is_numeric_dtype(df[id_col]):\n",
        "             print(f\"Warning: ID column '{id_col}' is not numeric. Skipping missing transaction check.\")\n",
        "             return []\n",
        "\n",
        "        df = df.sort_values(by=id_col)\n",
        "        if df[id_col].empty:\n",
        "            return []\n",
        "        # Handle potential non-integer IDs by converting to int for range creation\n",
        "        try:\n",
        "            min_id = int(df[id_col].min())\n",
        "            max_id = int(df[id_col].max())\n",
        "            expected_ids = set(range(min_id, max_id + 1))\n",
        "            actual_ids = set(df[id_col].astype(int)) # Convert actual IDs to int as well\n",
        "            missing_ids = sorted(list(expected_ids - actual_ids))\n",
        "            return missing_ids\n",
        "        except ValueError as e:\n",
        "             print(f\"Error converting ID column '{id_col}' to integer: {e}. Skipping missing transaction check.\")\n",
        "             return []\n",
        "\n",
        "\n",
        "    missing_purchase_invoices = find_missing(purchase_invoices_df, 'Invoice Number')\n",
        "    missing_sales_invoices = find_missing(sales_invoices_df, 'Invoice number')\n",
        "    missing_receipts = find_missing(receipts_df, 'Receipt Number')\n",
        "\n",
        "    return {\n",
        "        \"missing_purchase_invoices\": missing_purchase_invoices,\n",
        "        \"missing_sales_invoices\": missing_sales_invoices,\n",
        "        \"missing_receipts\": missing_receipts\n",
        "    }\n",
        "\n",
        "\n",
        "def compare_bank_statement_receipts(bank_statement_df, receipts_df):\n",
        "    \"\"\"Compares bank statement and receipts.\"\"\"\n",
        "    if bank_statement_df is None or receipts_df is None:\n",
        "        return {}\n",
        "    # Ensure date columns are datetime objects before comparison\n",
        "    bank_statement_df = preprocess_dates(bank_statement_df, ['Date'])\n",
        "    receipts_df = preprocess_dates(receipts_df, ['Date'])\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    bank_statement_df = bank_statement_df.dropna(subset=['Date'])\n",
        "    receipts_df = receipts_df.dropna(subset=['Date'])\n",
        "\n",
        "\n",
        "    # Convert relevant columns to a consistent type for comparison (e.g., string or numeric)\n",
        "    # Ensure 'Cr' and 'Amount' are numeric\n",
        "    bank_statement_df['Cr'] = pd.to_numeric(bank_statement_df['Cr'], errors='coerce').fillna(0)\n",
        "    receipts_df['Amount'] = pd.to_numeric(receipts_df['Amount'], errors='coerce').fillna(0)\n",
        "\n",
        "    # Convert identifier columns to string to avoid type mismatches during comparison\n",
        "    bank_statement_df['Detail'] = bank_statement_df['Detail'].astype(str)\n",
        "    receipts_df['Invoice Number'] = receipts_df['Invoice Number'].astype(str)\n",
        "    receipts_df['Receipt Number'] = receipts_df['Receipt Number'].astype(str)\n",
        "\n",
        "\n",
        "    # More robust comparison logic\n",
        "    # receipts not on bank: find rows in receipts_df that don't have a match in bank_statement_df\n",
        "    # based on Date, Amount, and potentially Invoice Number (or Receipt Number depending on mapping)\n",
        "    # This fuzzy matching with isin(df.to_dict('list')) is generally not reliable for comparisons\n",
        "    # Consider merging or more explicit comparison logic.\n",
        "\n",
        "    # Let's assume we want to match based on Date and Amount, and potentially Invoice/Receipt number as a detail\n",
        "    # Create a unique identifier for merging/comparison if possible\n",
        "\n",
        "    # Option 1: Merge and identify non-matches\n",
        "    merged_receipts_bank = pd.merge(\n",
        "        receipts_df,\n",
        "        bank_statement_df,\n",
        "        left_on=['Date', 'Amount'], # Assuming Amount in receipts matches Cr in bank\n",
        "        right_on=['Date', 'Cr'],\n",
        "        how='left',\n",
        "        indicator=True\n",
        "    )\n",
        "    # receipts not found in bank\n",
        "    receipts_not_on_bank = merged_receipts_bank[merged_receipts_bank['_merge'] == 'left_only'][receipts_df.columns] # Keep only receipts columns\n",
        "\n",
        "    # bank statement not on receipts\n",
        "    merged_bank_receipts = pd.merge(\n",
        "        bank_statement_df,\n",
        "        receipts_df,\n",
        "        left_on=['Date', 'Cr'],\n",
        "        right_on=['Date', 'Amount'],\n",
        "        how='left',\n",
        "        indicator=True\n",
        "    )\n",
        "    # bank entries not found in receipts\n",
        "    bank_statement_not_on_receipts = merged_bank_receipts[merged_bank_receipts['_merge'] == 'left_only'][bank_statement_df.columns] # Keep only bank columns\n",
        "\n",
        "    # Transactions with different amounts - Requires a common identifier other than just Date and Amount\n",
        "    # If 'Detail' in bank_statement_df corresponds to 'Receipt Number' in receipts_df for receipts transactions:\n",
        "    merged_amount_check = pd.merge(\n",
        "        bank_statement_df,\n",
        "        receipts_df,\n",
        "        left_on=['Date', 'Detail'], # Assuming Detail maps to Receipt Number for receipts\n",
        "        right_on=['Date', 'Receipt Number'],\n",
        "        how='inner' # Only look at transactions present in both based on Date and identifier\n",
        "    )\n",
        "\n",
        "    # Filter for rows where amounts don't match\n",
        "    amount_differences = merged_amount_check[merged_amount_check['Cr'] != merged_amount_check['Amount']]\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"receipts_not_on_bank\": receipts_not_on_bank,\n",
        "        \"bank_statement_not_on_receipts\": bank_statement_not_on_receipts,\n",
        "        \"amount_differences\": amount_differences\n",
        "    }\n",
        "\n",
        "\n",
        "def compare_bank_statement_supplier(bank_statement_df, supplier_statements_df):\n",
        "    \"\"\"Compares bank statement and supplier statements.\"\"\"\n",
        "    if bank_statement_df is None or supplier_statements_df is None:\n",
        "        return {}\n",
        "\n",
        "    # Ensure date columns are datetime objects before comparison\n",
        "    bank_statement_df = preprocess_dates(bank_statement_df, ['Date'])\n",
        "    supplier_statements_df = preprocess_dates(supplier_statements_df, ['Date'])\n",
        "\n",
        "    # Drop rows where date conversion failed\n",
        "    bank_statement_df = bank_statement_df.dropna(subset=['Date'])\n",
        "    supplier_statements_df = supplier_statements_df.dropna(subset=['Date'])\n",
        "\n",
        "    # Ensure relevant columns are numeric\n",
        "    bank_statement_df['Cr'] = pd.to_numeric(bank_statement_df['Cr'], errors='coerce').fillna(0)\n",
        "    supplier_statements_df['Credit (Payments/Credit Notes Applied)'] = pd.to_numeric(supplier_statements_df['Credit (Payments/Credit Notes Applied)'], errors='coerce').fillna(0)\n",
        "\n",
        "    # Ensure identifier columns are string\n",
        "    bank_statement_df['Detail'] = bank_statement_df['Detail'].astype(str)\n",
        "    supplier_statements_df['Payment Ref #Invoice number'] = supplier_statements_df['Payment Ref #Invoice number'].astype(str)\n",
        "\n",
        "\n",
        "    # supplier payments not on bank\n",
        "    merged_supplier_bank = pd.merge(\n",
        "        supplier_statements_df,\n",
        "        bank_statement_df,\n",
        "        left_on=['Date', 'Credit (Payments/Credit Notes Applied)'], # Assuming Payment Amount matches Cr in bank\n",
        "        right_on=['Date', 'Cr'],\n",
        "        how='left',\n",
        "        indicator=True\n",
        "    )\n",
        "    supplier_payments_not_on_bank = merged_supplier_bank[merged_supplier_bank['_merge'] == 'left_only'][supplier_statements_df.columns] # Keep supplier columns\n",
        "\n",
        "    # bank statement payments not on supplier\n",
        "    merged_bank_supplier = pd.merge(\n",
        "        bank_statement_df,\n",
        "        supplier_statements_df,\n",
        "        left_on=['Date', 'Cr'],\n",
        "        right_on=['Date', 'Credit (Payments/Credit Notes Applied)'],\n",
        "        how='left',\n",
        "        indicator=True\n",
        "    )\n",
        "    bank_statement_payments_not_on_supplier = merged_bank_supplier[merged_bank_supplier['_merge'] == 'left_only'][bank_statement_df.columns] # Keep bank columns\n",
        "\n",
        "\n",
        "    # Transactions with different amounts - Requires a common identifier\n",
        "    # If 'Detail' in bank_statement_df corresponds to 'Payment Ref #Invoice number' in supplier_statements_df for payment transactions:\n",
        "    merged_amount_diff = pd.merge(\n",
        "        bank_statement_df,\n",
        "        supplier_statements_df,\n",
        "        left_on=['Date', 'Detail'], # Assuming Detail maps to Payment Ref #Invoice number\n",
        "        right_on=['Date', 'Payment Ref #Invoice number'],\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    amount_differences = merged_amount_diff[\n",
        "        merged_amount_diff['Cr'] != merged_amount_diff['Credit (Payments/Credit Notes Applied)']\n",
        "    ]\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"supplier_payments_not_on_bank\": supplier_payments_not_on_bank,\n",
        "        \"bank_statement_payments_not_on_supplier\": bank_statement_payments_not_on_supplier,\n",
        "        \"amount_differences\": amount_differences\n",
        "    }\n",
        "\n",
        "# --- 5. Step 5: Integrating with Streamlit ---\n",
        "# This function is intended for use in a Streamlit app (app.py)\n",
        "# It should not be in a Jupyter notebook cell that's executed sequentially\n",
        "# without the Streamlit context.\n",
        "# To prevent errors, this function and the related Streamlit UI code below it\n",
        "# should be moved to your app.py file.\n",
        "\n",
        "# def display_audit_results(analysis_results):\n",
        "#     \"\"\"Displays the audit analysis results in Streamlit.\"\"\"\n",
        "#     # Note: This function is intended to be used within a Streamlit application\n",
        "#     # where 'st' is imported. The code below assumes 'st' is available in that context.\n",
        "\n",
        "#     # Import streamlit if running this function outside of a full Streamlit app\n",
        "#     # try:\n",
        "#     #     import streamlit as st\n",
        "#     # except ImportError:\n",
        "#     #     print(\"Streamlit is not installed. Please install it to use this function.\")\n",
        "#     #     return\n",
        "\n",
        "#     st.subheader(\"Audit Analysis Results\")\n",
        "\n",
        "#     if \"error\" in analysis_results:\n",
        "#         st.error(analysis_results[\"error\"])\n",
        "#         return\n",
        "\n",
        "#     st.subheader(\"Bank Statement vs. Supplier Statements Comparison\")\n",
        "#     st.write(analysis_results[\"llm_explanation_supplier\"])\n",
        "#     st.write(\"Supplier payments not on bank statement\",analysis_results[\"bank_supplier_comparison\"][\"supplier_payments_not_on_bank\"])\n",
        "#     st.write(\"Bank statement payments not on supplier statements\",analysis_results[\"bank_supplier_comparison\"][\"bank_statement_payments_not_on_supplier\"])\n",
        "#     st.write(\"Transactions with different amounts\",analysis_results[\"bank_supplier_comparison\"][\"amount_differences\"])\n",
        "\n",
        "#     st.subheader(\"Missing Transaction Checks\")\n",
        "#     st.write(analysis_results[\"llm_explanation_missing\"])\n",
        "#     st.write(\"Missing Purchase Invoices:\", analysis_results[\"missing_transactions\"][\"missing_purchase_invoices\"])\n",
        "#     st.write(\"Missing Sales Invoices:\", analysis_results[\"missing_transactions\"][\"missing_sales_invoices\"])\n",
        "#     st.write(\"Missing Receipts:\", analysis_results[\"missing_transactions\"][\"missing_receipts\"])\n",
        "\n",
        "#     st.subheader(\"Bank Statement vs. Receipts Comparison\")\n",
        "#     st.write(analysis_results[\"llm_explanation_receipts\"])\n",
        "#     st.write(\"Receipts not on bank statement\",analysis_results[\"bank_receipts_comparison\"][\"receipts_not_on_bank\"])\n",
        "#     st.write(\"Transactions only in Bank Statement:\", analysis_results[\"bank_receipts_comparison\"][\"bank_statement_not_on_receipts\"])\n",
        "#     st.write(\"Transactions with different amounts:\", analysis_results[\"bank_receipts_comparison\"][\"amount_differences\"])\n",
        "\n",
        "# The Streamlit file uploading and button logic below should be in your separate Streamlit application file (e.g., app.py)\n",
        "# and not in this Jupyter notebook cell. The lines below are commented out to prevent the IndentationError in the notebook.\n",
        "\n",
        "# # Store the uploaded files in session state and use them later\n",
        "# if 'bank_statement_file' not in st.session_state:\n",
        "#   st.session_state.bank_statement_file = None\n",
        "# if 'receipts_file' not in st.session_state:\n",
        "#   st.session_state.receipts_file = None\n",
        "# if 'supplier_statements_file' not in st.session_state:\n",
        "#   st.session_state.supplier_statements_file = None\n",
        "# if 'purchase_invoices_file' not in st.session_state:\n",
        "#   st.session_state.purchase_invoices_file = None\n",
        "# if 'sales_invoices_file' not in st.session_state:\n",
        "#   st.session_state.sales_invoices_file = None\n",
        "\n",
        "# # ... (Streamlit code from Step 2 - app.py)\n",
        "# elif choice == \"Audit Analysis\":\n",
        "#   st.subheader(\"Upload Financial Data\")\n",
        "#   st.write(\"Upload CSV files for AI-powered audit analysis.\")\n",
        "\n",
        "#   bank_statement_file = st.file_uploader(\"Bank Statement (CSV)\", type=\"csv\")\n",
        "#   receipts_file = st.file_uploader(\"Receipts (CSV)\", type=\"csv\")\n",
        "#   supplier_statements_file = st.file_uploader(\"Supplier Statements (CSV)\", type=\"csv\")\n",
        "#   purchase_invoices_file = st.file_uploader(\"Purchase Invoices (CSV)\", type=\"csv\")\n",
        "#   sales_invoices_file = st.file_uploader(\"Sales Invoices (CSV)\", type=\"csv\")\n",
        "\n",
        "#   if bank_statement_file and receipts_file and supplier_statements_file and purchase_invoices_file and sales_invoices_file:\n",
        "#   st.success(\"Files uploaded. Click 'Analyze' to start AI audit analysis.\")\n",
        "\n",
        "#   # Store the file in session state\n",
        "#   st.session_state.bank_statement_file = bank_statement_file\n",
        "#   st.session_state.receipts_file = receipts_file\n",
        "#   st.session_state.supplier_statements_file = supplier_statements_file\n",
        "#   st.session_state.purchase_invoices_file = purchase_invoices_file\n",
        "#   st.session_state.sales_invoices_file = sales_invoices_file\n",
        "\n",
        "#   if st.button(\"Analyze\"):\n",
        "#   st.write(\"Running AI-powered analysis...\")\n",
        "#   analysis_results = analyze_audit_data(\n",
        "#   bank_statement_file, supplier_statements_file,\n",
        "#   purchase_invoices_file, sales_invoices_file, receipts_file #order changed\n",
        "#   )\n",
        "#   display_audit_results(analysis_results)\n",
        "\n",
        "# # Example Usage (for testing in Colab)\n",
        "# #if __name__ == '__main__':\n",
        "# #  #  Create sample DataFrames (replace with your actual data)\n",
        "# #  bank_statement_data = {'Date': ['2024-01-01', '2024-01-05', '2024-01-10', '2024-01-15', '2024-01-20'],\n",
        "# #  'Detail': ['Payment', 'Receipt', 'Payment', 'Anomaly', 'Receipt'],\n",
        "# #  'Customer/Supplier name' : ['A','B','C','D','E'],\n",
        "# #  'Cr': [100, 200, 150, 1000, 250],\n",
        "# #  'Balance': [1000, 1200, 1050, 50, 300]}\n",
        "# #  receipts_data = {'Date': ['2024-01-05', '2024-01-10', '2024-01-12'],\n",
        "# #  'Receipt Number': [101, 102, 103],\n",
        "# #  'Customer Name' : ['B','C','F'],\n",
        "# #  'Invoice Number' : [1,2,3],\n",
        "# #  'Amount': [200, 150, 250]}\n",
        "# #  supplier_statements_data = {'Date': ['2024-01-01', '2024-01-1"
      ],
      "metadata": {
        "id": "_jmwm6k9rCni"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oLPXd3Pufkx"
      },
      "source": [
        "# Reconciliation Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbg0CxbVzEDW"
      },
      "source": [
        "The goal is to detect mismatched transactions, which is important for account reconciliation and fraud detection. For example, if I pay UMD tuition, the transaction appears on the UMD bank statement but is not reflected in my student billing account. This project will examine:\n",
        "\n",
        "Matching transaction records from different sources, such as:\n",
        "\n",
        "Bank statements vs. receipts\n",
        "\n",
        "Bank statements vs. supplier statements\n",
        "\n",
        "General ledger vs. purchase invoices, sales invoices, and supplier statements\n",
        "\n",
        "Missing transaction sequences in supplier invoices, customer invoices, and receipts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMGLlO7O6fSM"
      },
      "source": [
        "**QUERIES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cv9hKHR1qWD"
      },
      "source": [
        "##1. Bank statement vs Receipts\n",
        "\n",
        "**To compare:**\n",
        "\n",
        "1.a) Which transactions were recorded as received on receipts file, yet the receipt does not appear on the bank statement?\n",
        "\n",
        "1.b) Which payments are on the bank statement but do not appear on the receipts file ?\n",
        "\n",
        "1.c)Which transactions appear on both the bank statement and receipts file but have different amounts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAbzdWwEAXSw"
      },
      "source": [
        " 2. Bank statements vs Supplier statements\n",
        "\n",
        " To compare:\n",
        " 2.a) Which transactions were recorded as a payment in supplier statements file , yet the rec does not appear on the bank statement?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMYyRJNmvfyo"
      },
      "source": [
        "# GPT EXPLANATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8W7kFNyvlx1"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # Replace this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNj2n05ovopM"
      },
      "outputs": [],
      "source": [
        "def explain(row):\n",
        "    prompt = f\"\"\"Audit Issue:\\n\\nSource: {row['source']}\\nType: {row['issue_type']}\\nDetails: {row['details']}\\n\\nPlease explain in plain English why this is an audit concern.\"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"GPT error: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KizJIsRvrTw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "66d81348-c120-4303-e3fc-a2fa7f3760a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'source'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'source'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8aba6eb5f3a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Turn into DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_issues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0missues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_issues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'explanation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_issues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-09a1038c0864>\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\"\"Audit Issue:\\n\\nSource: {row['source']}\\nType: {row['issue_type']}\\nDetails: {row['details']}\\n\\nPlease explain in plain English why this is an audit concern.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         response = openai.ChatCompletion.create(\n\u001b[1;32m      5\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'source'"
          ]
        }
      ],
      "source": [
        "# Turn into DataFrame\n",
        "df_issues = pd.DataFrame(issues)\n",
        "df_issues['explanation'] = df_issues.apply(explain, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXH52arer1Z1"
      },
      "source": [
        "# Step 2 .Implementing the Landing Page and UI (Streamlit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "75i8h8oqrwsu",
        "outputId": "cbde19d5-bebd-4585-c6aa-24417a5c3fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import openai\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# --- Helper function for styling ---\n",
        "def local_css(file_name):\n",
        "    with open(file_name) as f:\n",
        "        st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "# Check if style.css exists, if not, create a minimal one\n",
        "if not os.path.exists(\"style.css\"):\n",
        "    with open(\"style.css\", \"w\") as f:\n",
        "        f.write(\"\"\"\n",
        "body {\n",
        " font-family: Arial, sans-serif;\n",
        " color: #333;\n",
        "}\n",
        ".st-header {\n",
        " background-color: #f0f2f6;\n",
        " padding: 10px;\n",
        " border-bottom: 1px solid #ccc;\n",
        "}\n",
        ".st-subheader {\n",
        " color: #444;\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "local_css(\"style.css\")\n",
        "\n",
        "# --- Header Section ---\n",
        "st.header(\"AI-Powered Audit Assistant\")\n",
        "st.subheader(\"Automate reconciliation and discrepancy detection with AI.\")\n",
        "\n",
        "# --- Navigation ---\n",
        "menu = [\"Home\", \"Audit Analysis\", \"About Us\", \"Contact\"]\n",
        "choice = st.sidebar.selectbox(\"Menu\", menu)\n",
        "\n",
        "if choice == \"Home\":\n",
        "    st.subheader(\"Streamline Your Audit Workflow\")\n",
        "    st.write(\"\"\"\n",
        "    - Automate time-consuming reconciliation.\n",
        "    - Detect discrepancies with high accuracy using AI.\n",
        "    - Get expert-level insights and explanations.\n",
        "    \"\"\")\n",
        "    st.subheader(\"Key Audit Analysis Features\")\n",
        "    st.write(\"• AI-Powered Discrepancy Detection\")\n",
        "    st.write(\"• Bank Statement vs. Receipts\")\n",
        "    st.write(\"• Bank Statement vs. Supplier Statements\")\n",
        "    st.write(\"• Missing Transactions\")\n",
        "    st.subheader(\"Request a Demo\")\n",
        "    st.button(\"Schedule a Demo\")\n",
        "\n",
        "elif choice == \"Audit Analysis\":\n",
        "    st.subheader(\"Upload Financial Data\")\n",
        "    st.write(\"Upload CSV files for AI-powered audit analysis.\")\n",
        "\n",
        "    bank_statement_file = st.file_uploader(\"Bank Statement (CSV)\", type=\"csv\")\n",
        "    receipts_file = st.file_uploader(\"Receipts (CSV)\", type=\"csv\")\n",
        "    supplier_statements_file = st.file_uploader(\"Supplier Statements (CSV)\", type=\"csv\")\n",
        "    purchase_invoices_file = st.file_uploader(\"Purchase Invoices (CSV)\", type=\"csv\")\n",
        "    sales_invoices_file = st.file_uploader(\"Sales Invoices (CSV)\", type=\"csv\")\n",
        "\n",
        "    if bank_statement_file and receipts_file and supplier_statements_file and purchase_invoices_file and sales_invoices_file:\n",
        "        st.success(\"Files uploaded. Click 'Analyze' to start AI audit analysis.\")\n",
        "        if st.button(\"Analyze\"):\n",
        "            st.write(\"Running AI-powered analysis...\")\n",
        "            # Dummy placeholder\n",
        "            st.info(\"Analysis complete. Display results here.\")\n",
        "\n",
        "elif choice == \"About Us\":\n",
        "    st.subheader(\"About Data Consultants & Architects\")\n",
        "    st.write(\"AI-powered solutions for finance.\")\n",
        "\n",
        "elif choice == \"Contact\":\n",
        "    st.subheader(\"Contact Us\")\n",
        "    st.write(\"Get in touch.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CnfygoGEibcS",
        "outputId": "ffbe80fd-3424-4b75-b327-c2f64d60baaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!npm install -g localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84MS1Maxiqa0",
        "outputId": "e4961899-5409-4337-f58c-4fca5e667f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0Kyour url is: https://light-guests-mate.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Run Streamlit app in the background\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Start streamlit in background\n",
        "subprocess.Popen(['streamlit', 'run', 'app.py'])\n",
        "\n",
        "# Expose port 8501 with localtunnel\n",
        "!npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHi_g-8y1er3"
      },
      "source": [
        "# Step 3: GitHub Integration"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "N5sXwsqxqtp1"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}